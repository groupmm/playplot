{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Advanced Examples\n",
    "(not yet final)\n",
    "\n",
    "Some extra files not provided in this repo are necessary!\n",
    "See ``example_data/__init__.py`` for details on how to provide them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import libfmp.b as lfb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from makeplotplayable import Session\n",
    "\n",
    "from example_data import *\n",
    "\n",
    "sr = 48000\n",
    "audio_a, _ = lfb.read_audio(simple_audio_file, mono=True, Fs=sr)\n",
    "\n",
    "def load_av_example_data():\n",
    "    WIDTH = 48 * 10\n",
    "    HEIGHT = 36 * 10\n",
    "\n",
    "    def frame2array(f):\n",
    "        img = cv2.cvtColor(f, cv2.COLOR_BGR2GRAY)\n",
    "        img = cv2.resize(img, (WIDTH, HEIGHT))\n",
    "        return np.array(img, dtype=np.uint8)\n",
    "\n",
    "    video_capture = cv2.VideoCapture(video_file)\n",
    "    arrays = list()\n",
    "    while True:\n",
    "        ret, frame = video_capture.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        array = frame2array(frame)\n",
    "        arrays.append(array)\n",
    "\n",
    "    array = np.stack(arrays, axis=0)\n",
    "\n",
    "    audio, _ = lfb.read_audio(audio_to_video_file, Fs=sr, mono=True)\n",
    "\n",
    "    return audio * 0.8, array\n",
    "\n",
    "\n",
    "audio_b, video = load_av_example_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Example 1:\n",
    "This example shows navigation between multiple audio files in one Session.\n",
    "It will loop and alternate between files.\n",
    "The time encodes the specific version,\n",
    "all versions are mapped linearly (in a real application these mappings would be more complicated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# combine audio clips into one to allow Session to play it\n",
    "combined_audio = np.concatenate((audio_a, audio_b))\n",
    "\n",
    "session01 = Session(combined_audio, sr, looping=True)\n",
    "session01.start()\n",
    "\n",
    "\n",
    "# noinspection PyShadowingNames\n",
    "@session01\n",
    "def plot(x, sr, durations, index, name):\n",
    "    start_times = np.zeros_like(durations)\n",
    "    for i in range(durations.shape[0] - 1):\n",
    "        start_times[i + 1] = start_times[i] + durations[i]\n",
    "\n",
    "    fig, ax, line = lfb.plot_signal(x, sr)\n",
    "\n",
    "    # map the time of all clips to a position\n",
    "    def time_to_pos(time_):\n",
    "        j = np.searchsorted(start_times, time_) - 1\n",
    "        time_ -= start_times[j]\n",
    "        progress = time_ / durations[j]\n",
    "        pos = progress * durations[index]\n",
    "        return pos\n",
    "\n",
    "    return fig, ax, {\"title\": name,\n",
    "                     \"custom_time_to_pos_function\": time_to_pos,\n",
    "                     \"custom_pos_to_time_function\": lambda pos: pos + start_times[\n",
    "                         index]}  # map to time depending on start time\n",
    "\n",
    "\n",
    "durations = np.array([audio_a.shape[0] / sr, audio_b.shape[0] / sr])\n",
    "\n",
    "# it is possible to use different plotting functions\n",
    "plot(audio_a, sr, durations, 0, 'C01 A')\n",
    "plot(audio_b, sr, durations, 1, 'C01 B')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Example 2:\n",
    "This example shows that animating a plot even allows for video playback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "session02 = Session(audio_b, sr, looping=True)\n",
    "session02.start()\n",
    "\n",
    "# noinspection PyShadowingNames\n",
    "@session02\n",
    "def plot_audio(x, sr):\n",
    "    fig, ax, line = lfb.plot_signal(x, sr)\n",
    "\n",
    "    #return the figure and the axis for the cursor as a tuple\n",
    "    return fig, ax, {\"title\": \"C02 Audio for Video\"}\n",
    "\n",
    "\n",
    "plot_audio(audio_b, sr)\n",
    "\n",
    "\n",
    "# noinspection PyShadowingNames\n",
    "@session02\n",
    "def plot_video(video):\n",
    "    fig = plt.figure()\n",
    "    ax = plt.subplot(1, 1, 1)\n",
    "\n",
    "    mat_plot = ax.imshow(np.zeros_like(video[0]), cmap='gray', vmin=0, vmax=255, interpolation='antialiased')\n",
    "\n",
    "    last_index = 0\n",
    "\n",
    "    # draw the correct frame (pos is frame index)\n",
    "    def draw_function(time_, pos, paused):\n",
    "        nonlocal last_index\n",
    "        # don't redraw if the frame has not changed\n",
    "        if last_index == pos:\n",
    "            return False\n",
    "\n",
    "        mat_plot.set(data=video[pos])\n",
    "        last_index = pos\n",
    "        return True\n",
    "\n",
    "    # implement play/pause functionality\n",
    "    pp_pressed = False\n",
    "\n",
    "    def on_key(event):\n",
    "        nonlocal pp_pressed\n",
    "        if event.key in [\" \", \"enter\"]:\n",
    "            pp_pressed = True\n",
    "\n",
    "    fig.canvas.mpl_connect('key_press_event', on_key)\n",
    "\n",
    "    def update_func(time_, pos, paused):\n",
    "        nonlocal pp_pressed\n",
    "        new_paused = paused ^ pp_pressed\n",
    "        pp_pressed = False\n",
    "        return time_, new_paused\n",
    "\n",
    "    return fig, ax, {\"title\": \"C02 Video\",\n",
    "                     \"draw_function\": draw_function,\n",
    "                     \"artists\": [mat_plot],\n",
    "                     \"override_update_function\": update_func,  # implement play/pause functionality + disable cursor\n",
    "                     \"custom_time_to_pos_function\": lambda time: int(\n",
    "                         min(video.shape[0] - 1, time * 30))}  # calculate the frame index\n",
    "\n",
    "\n",
    "plot_video(video)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Example 3:\n",
    "Test streaming of a long audio file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "session03 = Session.from_file(long_audio_file)\n",
    "session03.start()\n",
    "\n",
    "\n",
    "# noinspection PyShadowingNames\n",
    "@session03\n",
    "def plot(duration):\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    ax.plot(np.array([0, duration/3600]))\n",
    "    ax.set_xlabel(\"number of files played\")\n",
    "    ax.set_ylabel(\"time in hours\")\n",
    "\n",
    "    return fig, ax, {\"title\": \"C03 Streaming Example\"}\n",
    "\n",
    "\n",
    "plot(session03.duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Example 4:\n",
    "Test stereo playback, each ear will receive a different song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "combined_audio = np.stack((audio_a[:sr * 10], audio_b[:sr * 10]), axis=0)\n",
    "\n",
    "session04 = Session(combined_audio, sr)\n",
    "session04.start()\n",
    "\n",
    "\n",
    "# noinspection PyShadowingNames\n",
    "@session04\n",
    "def plot(audio, sr, title):\n",
    "    fig, ax, line = lfb.plot_signal(audio, sr)\n",
    "\n",
    "    return fig, ax, {\"title\": title}\n",
    "\n",
    "\n",
    "plot(combined_audio[0], sr, \"C04 Left\")\n",
    "plot(combined_audio[1], sr, \"C04 Right\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
