{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Advanced Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import libfmp.b as lfb\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from example_data import *\n",
    "\n",
    "# This file uses multiple Sessions, but only one will be open at a time, unless MULTI_SESSION is set to True\n",
    "MULTI_SESSION = False\n",
    "session_storage = dict()\n",
    "\n",
    "sr = 48000\n",
    "audio_a, _ = lfb.read_audio(simple_audio_file, mono=True, Fs=sr)\n",
    "\n",
    "def load_av_example_data():\n",
    "    WIDTH = 48 * 10\n",
    "    HEIGHT = 36 * 10\n",
    "\n",
    "    def frame2array(f):\n",
    "        img = cv2.cvtColor(f, cv2.COLOR_BGR2GRAY)\n",
    "        img = cv2.resize(img, (WIDTH, HEIGHT))\n",
    "        return np.array(img, dtype=np.uint8)\n",
    "\n",
    "    video_capture = cv2.VideoCapture(video_file)\n",
    "    arrays = list()\n",
    "    while True:\n",
    "        ret, frame = video_capture.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        array = frame2array(frame)\n",
    "        arrays.append(array)\n",
    "\n",
    "    array = np.stack(arrays, axis=0)\n",
    "\n",
    "    audio, _ = lfb.read_audio(audio_to_video_file, Fs=sr, mono=True)\n",
    "\n",
    "    return audio, array\n",
    "\n",
    "\n",
    "audio_b, video = load_av_example_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# advanced 1:\n",
    "# this example shows navigation between multiple audio files in one Session\n",
    "# it will loop and alternate between files\n",
    "# the time encodes the specific version\n",
    "# all versions are mapped linearly (in a real application these mappings would be more complicated)\n",
    "\n",
    "from makeplotplayable import Session\n",
    "\n",
    "# combine audio clips into one to allow Session to play it\n",
    "combined_audio = np.concatenate((audio_a, audio_b))\n",
    "\n",
    "session = Session(combined_audio, sr, looping=True)\n",
    "session.start()\n",
    "\n",
    "\n",
    "# noinspection PyShadowingNames\n",
    "@session\n",
    "def plot(x, sr, durations, index, name):\n",
    "    import numpy as np\n",
    "    import libfmp.b as lfb\n",
    "\n",
    "    start_times = np.zeros_like(durations)\n",
    "    for i in range(durations.shape[0] - 1):\n",
    "        start_times[i + 1] = start_times[i] + durations[i]\n",
    "\n",
    "    fig, ax, line = lfb.plot_signal(x, sr)\n",
    "\n",
    "    # map the time of all clips to a position\n",
    "    def time_to_pos(time):\n",
    "        j = np.searchsorted(start_times, time) - 1\n",
    "        time -= start_times[j]\n",
    "        progress = time / durations[j]\n",
    "        pos = progress * durations[index]\n",
    "        return pos\n",
    "\n",
    "    return fig, ax, {\"title\": name,\n",
    "                     \"custom_time_to_pos_function\": time_to_pos,\n",
    "                     \"custom_pos_to_time_function\": lambda pos: pos + start_times[\n",
    "                         index]}  # map to time depending on start time\n",
    "\n",
    "\n",
    "durations = np.array([audio_a.shape[0] / sr, audio_b.shape[0] / sr])\n",
    "\n",
    "# it is possible to use different plotting functions\n",
    "plot(audio_a, sr, durations, 0, 'A')\n",
    "plot(audio_b, sr, durations, 1, 'B')\n",
    "\n",
    "if MULTI_SESSION:\n",
    "    session_storage[\"advanced 1\"] = session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# advanced 2:\n",
    "# this example shows that animating a plot even allows for video playback\n",
    "\n",
    "from makeplotplayable import Session\n",
    "\n",
    "session = Session(audio_b, sr, looping=True)\n",
    "session.start()\n",
    "\n",
    "\n",
    "# noinspection PyShadowingNames\n",
    "@session\n",
    "def plot_audio(x, sr):\n",
    "    import libfmp.b as lfb\n",
    "\n",
    "    fig, ax, line = lfb.plot_signal(x, sr)\n",
    "\n",
    "    #return the figure and the axis for the cursor as a tuple\n",
    "    return fig, ax, {\"title\": \"Audio for Video\"}\n",
    "\n",
    "\n",
    "plot_audio(audio_b, sr)\n",
    "\n",
    "\n",
    "# noinspection PyShadowingNames\n",
    "@session\n",
    "def plot_video(video):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = plt.subplot(1, 1, 1)\n",
    "\n",
    "    mat_plot = ax.imshow(np.zeros_like(video[0]), cmap='gray', vmin=0, vmax=255, interpolation='antialiased')\n",
    "\n",
    "    last_index = 0\n",
    "\n",
    "    # draw the correct frame (pos is frame index)\n",
    "    def draw_function(time, pos, paused):\n",
    "        nonlocal last_index\n",
    "        # don't redraw if the frame has not changed\n",
    "        if last_index == pos:\n",
    "            return False\n",
    "\n",
    "        mat_plot.set(data=video[pos])\n",
    "        last_index = pos\n",
    "        return True\n",
    "\n",
    "    # implement play/pause functionality\n",
    "    pp_pressed = False\n",
    "\n",
    "    def on_key(event):\n",
    "        nonlocal pp_pressed\n",
    "        if event.key in [\" \", \"enter\"]:\n",
    "            pp_pressed = True\n",
    "\n",
    "    fig.canvas.mpl_connect('key_press_event', on_key)\n",
    "\n",
    "    def update_func(time, pos, paused):\n",
    "        nonlocal pp_pressed\n",
    "        new_paused = paused ^ pp_pressed\n",
    "        pp_pressed = False\n",
    "        return time, new_paused\n",
    "\n",
    "    return fig, ax, {\"title\": \"Video\",\n",
    "                     \"draw_function\": draw_function,\n",
    "                     \"artists\": [mat_plot],\n",
    "                     \"override_update_function\": update_func,  # implement play/pause functionality + disable cursor\n",
    "                     \"custom_time_to_pos_function\": lambda time: int(\n",
    "                         min(video.shape[0] - 1, time * 30))}  # calculate the frame index\n",
    "\n",
    "\n",
    "plot_video(video)\n",
    "\n",
    "if MULTI_SESSION:\n",
    "    session_storage[\"advanced 2\"] = session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# advanced 3:\n",
    "# Example to test streaming\n",
    "\n",
    "from makeplotplayable import Session\n",
    "\n",
    "session = Session.from_file(long_audio_file)\n",
    "session.start()\n",
    "\n",
    "\n",
    "# noinspection PyShadowingNames\n",
    "@session\n",
    "def plot(duration):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    ax.plot(np.array([0, duration]))\n",
    "\n",
    "    return fig, ax, {\"title\": \"Streaming Example\"}\n",
    "\n",
    "\n",
    "plot(session.duration)\n",
    "\n",
    "if MULTI_SESSION:\n",
    "    session_storage[\"advanced 3\"] = session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "# advanced 4:\n",
    "# Stereo Test\n",
    "\n",
    "from makeplotplayable import Session\n",
    "\n",
    "combined_audio = np.stack((audio_a[:sr * 10], audio_b[:sr * 10]), axis=0)\n",
    "\n",
    "session = Session(combined_audio, sr)\n",
    "session.start()\n",
    "\n",
    "\n",
    "# noinspection PyShadowingNames\n",
    "@session\n",
    "def plot(audio, sr, title):\n",
    "    import libfmp.b as lfb\n",
    "\n",
    "    fig, ax, line = lfb.plot_signal(audio, sr)\n",
    "\n",
    "    return fig, ax, {\"title\": title}\n",
    "\n",
    "\n",
    "plot(combined_audio[0], sr, \"Left\")\n",
    "plot(combined_audio[1], sr, \"Right\")\n",
    "\n",
    "time.sleep(10)\n",
    "\n",
    "if MULTI_SESSION:\n",
    "    session_storage[\"advanced 4\"] = session"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
